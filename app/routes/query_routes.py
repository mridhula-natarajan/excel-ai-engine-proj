from fastapi import APIRouter, HTTPException,UploadFile, File,Form
from fastapi import Body
from fastapi.responses import JSONResponse, FileResponse
from typing import Dict, Any, Optional

import difflib
import os
import json
import pandas as pd
import numpy as np
import datetime

from app.core.file_manager import dataset_cache, load_excel_preview 
from app.core.llm_interpreter import call_llm_for_plan, call_llm_verifier
from app.core.executor import execute_plan
from app.core.logger import get_logger

logger = get_logger(__name__)
logger.info("LOADED: %s", os.path.abspath(__file__))

router = APIRouter()

def make_json_serializable(obj):
    """Convert objects into JSON-serializable types."""
    if isinstance(obj, pd.DataFrame):
        return obj.head(10).to_dict(orient="records")
    elif isinstance(obj, pd.Series):
        return obj.to_dict()
    elif isinstance(obj, (np.integer, np.int64)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64)):
        return float(obj)
    elif isinstance(obj, (np.bool_, bool)):
        return bool(obj)
    elif isinstance(obj, (pd.Timestamp, datetime.datetime)):
        return obj.isoformat()
    elif isinstance(obj, dict):
        return {k: make_json_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [make_json_serializable(i) for i in obj]
    else:
        try:
            json.dumps(obj)
            return obj
        except Exception:
            return str(obj)

@router.post("/query")
async def query_excel(payload: Dict[str, Any] = Body(...)):
    logger.info("Query Route Executing")
    """Handles user queries on uploaded Excel files by generating, executing, and verifying the LLM generated plan."""
    filename = payload.get("filename")
    sheet = payload.get("sheet")
    user_query = payload.get("query")
    logger.info(f" Received query request | file={filename}, sheet={sheet}, query={user_query}")

    if not filename or not user_query:
        raise HTTPException(status_code=400, detail="filename and query are required")

    if filename not in dataset_cache:
        ##where input files are saved.
        uploads_dir = "uploads"
        file_path = os.path.join(uploads_dir, filename)
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="file not found")
        _ = load_excel_preview(file_path)

    sheets = dataset_cache.get(filename)
    if sheet is None:
        # pick first sheet if multiple sheets present
        sheet = list(sheets.keys())[0]
    if sheet not in sheets:
        raise HTTPException(status_code=404, detail="sheet not found in file")

    df = sheets[sheet]

    # Provide columns to LLM to improve results
    sample_columns = list(df.columns.astype(str))[:50]

    try:
        plan_str = call_llm_for_plan(user_query, sample_columns=sample_columns)
        logger.info(f"LLM raw output: {plan_str}")

        # Parse LLM output
        try:
            plan = json.loads(plan_str) if isinstance(plan_str, str) else plan_str
        except Exception as e:
            logger.warning(f" Failed to parse LLM output as JSON: {e}")
            raise HTTPException(status_code=500, detail="Invalid LLM response format")

        logger.info(f" Parsed plan operation")
    except ValueError as e:
        raise HTTPException(status_code=500, detail=str(e))
    
    # 2) Execute the plan generated by LLM
    other_tables = {k: v for k, v in sheets.items() if k != sheet}  # allow joins with other sheets in same file
    file_path = os.path.join("uploads", filename)
    plan["input_path"] = file_path 
    exec_out = execute_plan(df.copy(), plan, other_tables)

    if exec_out.get("status") != "ok":
        return JSONResponse(content={"status": "error", "message": exec_out.get("message")}, status_code=400)

    result_preview = exec_out.get("preview", [])

    # 3) Verification by LLM if the plan LLM opts for it
    if plan.get("verify", False):
        verifier = call_llm_verifier(user_query, plan, result_preview)
    else:
        verifier = {"ok": True, "note": "no verification requested"}

    # Return preview + operation metadata instead of full dataframe
    return JSONResponse(content={
    "status": "ok",
    "plan": plan,
    "message": exec_out.get("message"),
    "preview": result_preview,
    "verifier": verifier,
    "file_path": exec_out.get("file_path") 
})

@router.get("/download_result")
async def download_result(filename: str):
    """Endpoint to download result Excel file saved under results/."""
    file_path = os.path.join("results", filename)
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="Result file not found")

    return FileResponse(
        file_path,
        filename=filename,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

def normalize_operation(predicted_op: str) -> str:
    valid_ops = [
        "aggregate", "math", "filter", "pivot",
        "unpivot", "join", "date_ops",
        "text_analysis", "describe", "sample", "multi_step"
    ]
    predicted_op = predicted_op.strip().lower()
    match = difflib.get_close_matches(predicted_op, valid_ops, n=1, cutoff=0.4)
    return match[0] if match else predicted_op

@router.post("/analyze_and_query")
async def analyze_and_query(
    file: UploadFile = File(..., description="Main Excel file"),
    query: str = Form(..., description="Natural language query to perform"),
    other_file: Optional[UploadFile] = File(
        None, description="Optional second Excel file (for join or comparison)"
    ),
):
    """Upload one or two Excel files and perform analysis in a single API call."""

    try:
        upload_dir = "uploads"
        os.makedirs(upload_dir, exist_ok=True)

        main_path = os.path.join(upload_dir, file.filename)
        with open(main_path, "wb") as f:
            f.write(await file.read())
        df_main = pd.read_excel(main_path)

        df_others = {}
        if other_file:
            other_path = os.path.join(upload_dir, other_file.filename)
            with open(other_path, "wb") as f:
                f.write(await other_file.read())
            df_others["other_sheet"] = pd.read_excel(other_path)

        plan_str = call_llm_for_plan(query, sample_columns=list(df_main.columns))
        plan = json.loads(plan_str) if isinstance(plan_str, str) else plan_str

        # Add meta info for executor
        plan["input_path"] = main_path
        plan["query"] = query

        result = execute_plan(df_main, plan, other_tables=df_others or None)

        try:
            json_safe_result = make_json_serializable({
                k: v for k, v in result.items() if k != "result_df"
            })
        except Exception as e:
            logger.error(f"Serialization failed: {e}")
            json_safe_result = {"status": "error", "message": str(e)}

        if result.get("file_path"):
            json_safe_result["excel_saved"] = True
            json_safe_result["download_url"] = f"/api/v1/download_result?filename={os.path.basename(result['file_path'])}"
        else:
            json_safe_result["excel_saved"] = False

        return JSONResponse(content=json_safe_result)

    except Exception as e:
        logger.exception(" Error during analyze_and_query: %s", e)
        raise HTTPException(status_code=500, detail=f"Error during analyze_and_query: {str(e)}")
